{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2159df6f",
   "metadata": {
    "id": "2159df6f"
   },
   "source": [
    "# Pneumonia,  Chest Xray - InceptionV3\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1430b69b",
   "metadata": {
    "id": "1430b69b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(\"Do you want to run the training process? (y / n)\")\n",
    "i = input()\n",
    "if i == 'y':\n",
    "    train_model = True\n",
    "else:\n",
    "    train_model = False\n",
    "    \n",
    "fpath = \"/home/arttu/Documents/research/chest_xray/\"\n",
    "# fpath = \"hakkina7@triton.aalto.fi:/scratch/work/hakkina7/research/chest_xray/\"\n",
    "print(\"File path is {}\".format(fpath))\n",
    "\n",
    "# Set the device\n",
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(\"Device is {}\".format(device))\n",
    "\n",
    "# Set file name\n",
    "fname = 'inceptionV3.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d8a5",
   "metadata": {
    "id": "b6f0d8a5"
   },
   "source": [
    "## Data preprocessing\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7480215",
   "metadata": {
    "id": "a7480215"
   },
   "source": [
    "### Important: In contrast to the other models the inception_v3 expects tensors with a size of N x 3 x 299 x 299, so ensure your images are sized accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01b23bd",
   "metadata": {
    "id": "d01b23bd"
   },
   "outputs": [],
   "source": [
    "# Takes a while to run the mean and std calculation, so save the values here\n",
    "# NB: These have to be calculated again if the image size is changed\n",
    "# NB: Modifying the batch size doesn't matter, mean and std stay the same\n",
    "# mean = [0.485, 0.456, 0.406] # https://pytorch.org/hub/pytorch_vision_inception_v3/\n",
    "# std = [0.229, 0.224, 0.225] # https://pytorch.org/hub/pytorch_vision_inception_v3/\n",
    "\n",
    "h, w = (299, 299)\n",
    "# Get proper dataloader with normalized images\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((h, w)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor([0.0, 0.0, 0.0]), torch.Tensor([1.0, 1.0, 1.0]))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=fpath+\"data/train/\",\n",
    "                                           transform=transformations)\n",
    "testset = torchvision.datasets.ImageFolder(root=fpath+\"data/test/\",\n",
    "                                           transform=transformations)\n",
    "valset = torchvision.datasets.ImageFolder(root=fpath+\"data/val/\",\n",
    "                                           transform=transformations)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=8, shuffle=False)\n",
    "valloader = torch.utils.data.DataLoader(dataset=valset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"Show some images? (y / n)\")\n",
    "i = input()\n",
    "if i == 'y':\n",
    "    show = True\n",
    "else:\n",
    "    show = False\n",
    "\n",
    "if show:\n",
    "    # Show some images after transformations\n",
    "    loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=9, shuffle=True)\n",
    "    images, labels = next(iter(loader))\n",
    "    grid=torchvision.utils.make_grid(images, nrow=3)\n",
    "    plt.figure(figsize=(10,40))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e8498",
   "metadata": {
    "id": "2b2e8498"
   },
   "source": [
    "## Training\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45407b0",
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1634864254227,
     "user": {
      "displayName": "Arttu HÃ¤kkinen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02318314570735220246"
     },
     "user_tz": -180
    },
    "id": "a45407b0"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, trainloader, testloader, device, optimizer, loss_fn):\n",
    "    \"\"\"Training loop\"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        best_acc = 0\n",
    "        losses = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start = time.time()\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(images)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            correct += (labels == pred).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Batch {}/{}: {:.2f} seconds\".format(i+1, len(trainloader), time.time()-start))\n",
    "            start=time.time()\n",
    "        acc = 100 * correct/total\n",
    "        print(\"\\nEpoch {}:\\nMean loss {} - Correctly labeled training images {:.2f}%\".format(epoch+1,\n",
    "                                                                                           np.mean(losses),\n",
    "                                                                                           acc))\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        true = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "        preds = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "        probs = torch.zeros(0, dtype=torch.float, device='cpu')\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            for i, (images, labels) in enumerate(testloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                true = torch.cat([true, labels.view(-1)])\n",
    "                preds = torch.cat([preds, pred.view(-1)])\n",
    "                prob, _ = (F.softmax(outputs, dim=1)).topk(1, dim=1)\n",
    "                probs = torch.cat([probs, prob.view(-1)])\n",
    "                print(\"Batch {}/{}: {:.2f} seconds\".format(i+1, len(testloader), time.time()-start))\n",
    "                start=time.time()\n",
    "                \n",
    "        acc = 100 * correct/total\n",
    "        print(\"Classified {:.2f} % of test images correctly.\".format(\n",
    "            acc\n",
    "        ))\n",
    "        print(\"Precision on test set: {}\".format(\n",
    "            metrics.precision_score(true.numpy(), preds.numpy())\n",
    "        ))\n",
    "        print(\"Recall on test set: {}\".format(\n",
    "            metrics.recall_score(true.numpy(), preds.numpy())\n",
    "        ))\n",
    "        print(\"F1-score on test set: {}\".format(\n",
    "            metrics.f1_score(true.numpy(), preds.numpy())\n",
    "        ))\n",
    "        print(\"AUC score on test set: {}\".format(\n",
    "            metrics.roc_auc_score(true.numpy(), probs.numpy())\n",
    "        ))\n",
    "        print(\"Confusion matrix on test set:\")\n",
    "        print(pd.DataFrame(metrics.confusion_matrix(true.numpy(), preds.numpy()), \n",
    "                           columns=['pred as NEG', 'pred as POS'], \n",
    "                           index=['true class NEG', 'true class POS']))\n",
    "        print()\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if train_model:\n",
    "    print(\"Training InceptionV3 model for Chest X-ray Pneumonia classification task.\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = models.inception_v3(pretrained=False)\n",
    "    n_labels = 2\n",
    "    n_inputs = model.fc.in_features\n",
    "    model.fc = nn.Linear(n_inputs, n_labels)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Calculate weights for the weighted loss function. We need the weighted loss,\n",
    "    # because of the class imbalance that is present on the data sets. If\n",
    "    # weighted loss fails, try focal loss with alpha=0.25 and gamma=2.\n",
    "    n_samples = [1266, 3418]\n",
    "    weights = [1 / (x / sum(n_samples)) for x in n_samples]  # More weight on the samples that appear less\n",
    "    weights = torch.FloatTensor(weights).to(device)\n",
    "    print(\"Since there is class imbalance present in some of the data sets, use the following weights in the loss function:\")\n",
    "    print(weights)\n",
    "    print()\n",
    "    \n",
    "    # Train model\n",
    "    model = train(model=model,\n",
    "                  epochs=100,\n",
    "                  trainloader=trainloader,\n",
    "                  testloader=testloader,\n",
    "                  device=device,\n",
    "                  optimizer=optim.SGD(list(model.parameters()),\n",
    "                                      lr=1e-3,\n",
    "                                      momentum=0.9),\n",
    "                  loss_fn=nn.CrossEntropyLoss(weight=weights))\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), fpath+fname)\n",
    "    print(\"Model succesfully saved to {}\".format(fpath+fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ca569",
   "metadata": {
    "id": "0d3ca569"
   },
   "source": [
    "## Evaluate\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695343d2",
   "metadata": {
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1634864257975,
     "user": {
      "displayName": "Arttu HÃ¤kkinen",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02318314570735220246"
     },
     "user_tz": -180
    },
    "id": "695343d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, valloader, device):\n",
    "    \"\"\"Evaluate model performance on validation set\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "    preds = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "    probs = torch.zeros(0, dtype=torch.float, device='cpu')\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for i, (images, labels) in enumerate(valloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            true = torch.cat([true, labels.view(-1)])\n",
    "            preds = torch.cat([preds, pred.view(-1)])\n",
    "            prob, _ = (F.softmax(outputs, dim=1)).topk(1, dim=1)\n",
    "            probs = torch.cat([probs, prob.view(-1)])\n",
    "            print(\"Batch {}/{}: {:.2f} seconds\".format(i+1, len(valloader), time.time()-start))\n",
    "            start=time.time()\n",
    "    \n",
    "    acc = 100 * correct/total\n",
    "    print(\"\\nClassified {:.2f} % of validation images correctly.\".format(\n",
    "            acc\n",
    "        ))\n",
    "    print(\"Precision on validation set: {}\".format(\n",
    "        metrics.precision_score(true.numpy(), preds.numpy())\n",
    "    ))\n",
    "    print(\"Recall on validation set: {}\".format(\n",
    "        metrics.recall_score(true.numpy(), preds.numpy())\n",
    "    ))\n",
    "    print(\"F1-score on validation set: {}\".format(\n",
    "        metrics.f1_score(true.numpy(), preds.numpy())\n",
    "    ))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(true.numpy(), probs.numpy())\n",
    "    print(\"AUC score on validation set: {} or {}\".format(\n",
    "        metrics.roc_auc_score(true.numpy(), probs.numpy()),\n",
    "        metrics.auc(fpr, tpr)\n",
    "    ))\n",
    "    print(\"Confusion matrix on validation set:\")\n",
    "    print(pd.DataFrame(metrics.confusion_matrix(true.numpy(), preds.numpy()), \n",
    "                       columns=['pred as NEG', 'pred as POS'], \n",
    "                       index=['true class NEG', 'true class POS']))\n",
    "    print()\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % metrics.auc(fpr, tpr))\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    \n",
    "\n",
    "# Initialize model\n",
    "model = models.inception_v3(pretrained=False)\n",
    "n_labels = 2\n",
    "n_inputs = model.fc.in_features\n",
    "model.fc = nn.Linear(n_inputs, n_labels)\n",
    "\n",
    "# Load model params\n",
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(fpath+fname))\n",
    "    model.to(device)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(fpath+fname,\n",
    "                                     map_location=torch.device('cpu')))\n",
    "    \n",
    "print(\"Model succesfully loaded from {}\".format(fpath+fname))\n",
    "\n",
    "# Evaluate the model performance on validation set\n",
    "print(\"Evaluating the InceptionV3 model on the validation set.\")\n",
    "evaluate(model, valloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05f393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XRAY_INCEPTIONV3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
